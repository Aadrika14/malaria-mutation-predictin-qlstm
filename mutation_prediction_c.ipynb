{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"synthetic_malaria_mutation_dataset.csv\")\n",
    "\n",
    "# Use only 'Collection_Year' and 'mutation_label'\n",
    "df = df[['Geo_Location', 'Tissue_Specimen_Source', 'Collection_Year', 'mutation_label']]\n",
    "\n",
    "\n",
    "# Remove any rows with missing values (optional but recommended)\n",
    "df = df.dropna()\n",
    "\n",
    "# Split into train and test\n",
    "split = int(0.8 * len(df))\n",
    "df_train = df[:split].copy()\n",
    "df_test = df[split:].copy()\n",
    "\n",
    "# Define target and features\n",
    "features = [\"mutation_label\"]\n",
    "target = \"mutation_label\"\n",
    "\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "df_train[features] = scaler.fit_transform(df_train[features])\n",
    "df_test[features] = scaler.transform(df_test[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a, min_a=None, max_a=None):\n",
    "    if min_a is None:\n",
    "        min_a, max_a = np.min(a, axis=0), np.max(a, axis=0)\n",
    "    return (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Updated normalization function\n",
    "def normalize(df, features, min_val=None, max_val=None):\n",
    "    if min_val is None:\n",
    "        min_val = df[features].min()\n",
    "    if max_val is None:\n",
    "        max_val = df[features].max()\n",
    "\n",
    "    df_norm = df.copy()\n",
    "    df_norm[features] = (df[features] - min_val) / (max_val - min_val + 0.0001)\n",
    "    return df_norm, min_val, max_val\n",
    "\n",
    "# âœ… Use it like this (make sure `features` is already defined)\n",
    "df_train, min_train, max_train = normalize(df_train, features=features)\n",
    "df_test, _, _ = normalize(df_test, features=features, min_val=min_train, max_val=max_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Features shape: torch.Size([1, 3, 1])\n",
      "ðŸŽ¯ Target shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from QLSTM import SequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sequence_length = 3\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = SequenceDataset(df_train, target=target, features=features, sequence_length=sequence_length)\n",
    "test_dataset = SequenceDataset(df_test, target=target, features=features, sequence_length=sequence_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check\n",
    "X, y = next(iter(train_loader))\n",
    "print(\"âœ… Features shape:\", X.shape)\n",
    "print(\"ðŸŽ¯ Target shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test_model(data_loader, model, loss_function): \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def predict(data_loader, model):\n",
    "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
    "    function.\n",
    "    \"\"\"\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from QLSTM import ShallowRegressionLSTM\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_hidden_units = 7\n",
    "\n",
    "model = ShallowRegressionLSTM(\n",
    "    num_sensors=len(features),\n",
    "    hidden_units=num_hidden_units,\n",
    "    num_layers=1\n",
    ")\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 288\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Count number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "\n",
      "Epoch 0\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "classical_loss_train = []\n",
    "classical_loss_test = []\n",
    "print(\"Untrained test\\n--------\")\n",
    "# test_loss = test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for ix_epoch in range(num_epochs):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_loss = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_loss = test_model(test_loader, model, loss_function)\n",
    "    classical_loss_train.append(train_loss)\n",
    "    classical_loss_test.append(test_loss)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_eval_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ystar_col_Q = \"Model Forecast\"\n",
    "df_train[ystar_col_Q] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col_Q] = predict(test_eval_loader, model).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(range(len(df_test)), df_test['mutation_label'], label=\"Real Data\")\n",
    "plt.plot(range(len(df_test)), df_test[\"Model Forecast\"], label=\"LSTM Test Prediction\")\n",
    "plt.ylabel('Mutation Label')\n",
    "plt.xlabel('Samples')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(classical_loss_train, label='classical_loss_train')\n",
    "# plt.plot(classical_loss_test, label='classical_loss_test')\n",
    "pd.DataFrame(classical_loss_train).to_csv('LSTM_loss.csv', index=False)\n",
    "plt.title('Train loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate RMSE between actual and predicted mutation values\n",
    "train_rmse = math.sqrt(mean_squared_error(df_train[\"mutation_label\"], df_train[\"Model Forecast\"]))\n",
    "test_rmse = math.sqrt(mean_squared_error(df_test[\"mutation_label\"], df_test[\"Model Forecast\"]))\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # âœ… Make sure this is included\n",
    "\n",
    "# Calculate the accuracy of the model (tolerance = 0.1)\n",
    "def accuracy(y, y_star):\n",
    "    return np.mean(np.abs(y - y_star) < 0.1)\n",
    "\n",
    "train_accuracy = accuracy(df_train[\"mutation_label\"], df_train[\"Model Forecast\"])\n",
    "test_accuracy = accuracy(df_test[\"mutation_label\"], df_test[\"Model Forecast\"])\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Example: Assume predicted values are in a numpy array\n",
    "predicted_values = np.array([1.23, 4.56, 7.89])  # This is just a placeholder for your actual predicted values\n",
    "\n",
    "# Save the predicted values to a JSON file\n",
    "with open('prediction.json', 'w') as f:\n",
    "    json.dump(predicted_values.tolist(), f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlstm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
